[[fuzzy-query]]
=== 模糊查询

{ref}/query-dsl-fuzzy-query.html[`fuzzy` 查询]是((("typoes and misspellings", "fuzzy query")))((("fuzzy queries"))) `term` 查询的模糊等价。
也许你很少直接使用它，但是理解它是如何工作的，可以帮助你在更高级别的 `match` 查询中使用模糊性。

为了解它是如何运作的，我们首先索引一些文档：

[source,json]
-----------------------------------
POST /my_index/my_type/_bulk
{ "index": { "_id": 1 }}
{ "text": "Surprise me!"}
{ "index": { "_id": 2 }}
{ "text": "That was surprising."}
{ "index": { "_id": 3 }}
{ "text": "I wasn't surprised."}
-----------------------------------

现在我们可以为词 `surprize` 运行一个 `fuzzy` 查询：

[source,json]
-----------------------------------
GET /my_index/my_type/_search
{
  "query": {
    "fuzzy": {
      "text": "surprize"
    }
  }
}
-----------------------------------

`fuzzy` 查询是一个词项级别的查询，所以它不做任何分析。它通过某个词项以及指定的 `fuzziness` 查找到词典中所有的词项。
`fuzziness` 默认设置为 `AUTO` 。

在我们的例子中， `surprise` 比较 `surprise` 和 `surprised` 都在编辑距离 2 以内，
所以文档1和3匹配。我们能够减少匹配度 ，通过下面的查询方法只有 `surprise` 匹配：

[source,json]
-----------------------------------
GET /my_index/my_type/_search
{
  "query": {
    "fuzzy": {
      "text": {
        "value": "surprize",
        "fuzziness": 1
      }
    }
  }
}
-----------------------------------

==== 提高性能


`fuzzy` 查询的工作原理是给定原始词项及构造一个 _编辑自动机_&#x2014;((("fuzzy queries", "improving performance")))((("Levenshtein automation")))
像表示所有原始字符串指定编辑距离的字符串的一个大图表。


然后模糊查询使用自动机高效依次遍历词典中的所有匹配词项。
一旦收集了词典中存在的所有匹配项，就可以计算匹配文档列表。

当然，根据存储在索引中的数据类型，一个编辑距离2的模糊查询能够匹配一个非常大数量的词项同时执行效率会非常糟糕。
下面两个参数可以用来限制对性能的影响：


`prefix_length`::

((("prefix_length parameter")))不能被 ``模糊化'' 的初始字符数。
大部分的拼写错误发生在词的结尾，而不是词的开始。
例如通过将 `prefix_length` 设置为 `3`，你可能够显著降低匹配的词项数量。

`max_expansions`::

如果一个模糊查询扩展了三个或四个模糊选项，((("max_expansions parameter"))) 这些新的模糊选项也许是有意义的。如
果它产生1000个模糊选项，那么就基本没有意义了。
设置 `max_expansions` 用来限制将产生的模糊选项的总数量。模糊查询将收集匹配词项直到达到 `max_expansions` 的限制。
