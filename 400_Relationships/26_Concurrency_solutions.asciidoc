[[concurrency-solutions]]
=== 解决并发问题

问题在于当我们要允许多个人 _在同一时间_ 重命名文件或目录。想象一下，你正在重命名 `/clinton` 目录，其中包含了成百上千的文件。
同时，另一个用户对单个文件 `/clinton/projects/elasticsearch/README.txt` 进行了重命名。这个用户的操作修改，虽然在你的操作开始后进行，可能会更迅速的完成。


以下其中之一将会发生：

*   你决定了要使用的版本号，在这种情况下，当版本号与 `README.txt` 文件重命名产生冲突时，你大量的重命名操作将会失败。

*   你没有使用版本控制，你的变更将覆盖其他用户的变更。

问题的原因是 Elasticsearch 不支持 http://en.wikipedia.org/wiki/ACID_transactions[ACID transactions]。
((("ACID transactions"))) 对单个文件的变更是 ACIDic 的，但包含多个文档的变更不支持。

如果你的主要数据存储是关系数据库，并且 Elasticsearch 只是被作为一个搜索引擎((("relational databases", "Elasticsearch used with")))或作为一种方法来提高性能，
首先在数据库中执行变更动作，并且在成功后将这些变更复制到 Elasticsearch。通过这种方式，你将受益于数据库 ACID 事务支持，并且所有变更在 Elasticsearch 以正确的顺序发生变化。
并发在关系数据库中得到处理。

如果你不使用关系型存储，这些并发问题就需要在 Elasticsearch 事务水准进行处理。
以下是三个使用 ElasticSearch 的实用解决方案，所有这一切都涉及某种形式的锁：

* 全局锁
* 文档锁
* 树锁

[TIP]
==================================================

本节中描述的解决方案当使用一个外部系统替代 Elasticsearch 实现时，也可以运用相同的原理进行实施。

==================================================

[[global-lock]]
==== 全局锁

我们可以完全避免并发问题，通过在任何时间只允许一个进程来进行变更动作。((("locking", "global lock")))((("global lock")))
大多数的变更只涉及少量文件，并且将非常迅速的完成。一个顶级目录的重命名会对所有其他变更造成较长时间的阻塞，但这些变更多半不太频繁。

因为在 Elasticsearch 文档级别的变更支持 ACIDic，我们能够使用一个文档的存在或不存在作为一个全局锁。为了请求一个锁，我们尝试 `create` 全局锁文档：

[source,json]
--------------------------
PUT /fs/lock/global/_create
{}
--------------------------

如果该 `create` 由于冲突异常请求失败，说明另一个进程已被授予全局锁，我们将稍后重试。
如果它成功了，现在我们自豪的成为全局锁的主人，并且我们可以继续完成我们的变更。一旦完成，我们就必须通过删除全局锁文档来释放锁：

[source,json]
--------------------------
DELETE /fs/lock/global
--------------------------

依赖于变更的频繁程度，以及变更消耗了多长时间，一个全局性的锁可以对系统造成大幅度的性能限制。
我们可以增加更多的并行性，使我们的锁更细粒度。

[[document-locking]]
==== 文档锁

我们可以使用先前描述同样的技术来锁定个体文档，而不是锁定整个文件系统。((("locking", "document locking")))((("document locking")))
我们可以使用 <<scroll,scrolled search>> 检索所有的文档，这些文档会被变更影响因此每一个文档都创建了一个锁文件：

[source,json]
--------------------------
PUT /fs/lock/_bulk
{ "create": { "_id": 1}} <1>
{ "process_id": 123    } <2>
{ "create": { "_id": 2}}
{ "process_id": 123    }
--------------------------
<1> `lock` 文档的 ID 将与应被锁定的文件的 ID 相同。
<2> `process_id` 是一个唯一的 ID 代表要执行变更的过程。

如果一些文件已被锁定，部分的 `bulk` 请求将失败，我们将不得不再次尝试。

当然，如果我们试图再次锁定 _所有_ 的文件， 我们以前使用的 `create` 语句将会失败，因为任何文件都已被我们锁定！
我们需要使用一个 `update` 请求通过一个 `upsert` 参数以及这个 `script` ，而不是一个简单的 `create` 语句：

[source,groovy]
--------------------------
if ( ctx._source.process_id != process_id ) { <1>
  assert false;  <2>
}
ctx.op = 'noop'; <3>
--------------------------
<1> `process_id` 是传递到脚本的一个参数。
<2> `assert false` 将引发异常，导致更新失败。
<3> 将 `op` 从 `update` 更新到 `noop` 防止更新请求作出任何改变，但仍返回成功。

完整的 `update` 请求看起来像这样：

[source,json]
--------------------------
POST /fs/lock/1/_update
{
  "upsert": { "process_id": 123 },
  "script": "if ( ctx._source.process_id != process_id )
  { assert false }; ctx.op = 'noop';"
  "params": {
    "process_id": 123
  }
}
--------------------------

如果文档不存在，该 `upsert` 文档操作是和前面 `create` 请求相同的插入操作。但是，如果该文件 _确实_ 存在，该脚本查看存储在文档上的 `process_id` 。
如果 `process_id` 匹配，不进行更新动作（ `noop` ）但是脚本返回成功。如果是不同的， `assert false` 抛出一个异常，因此你知道该锁已失败。

一旦所有锁已成功创建，你就可以继续进行你的变更。

之后，你必须释放所有的锁，你可以通过检索所有的锁定文档并进行批量删除：


[source,json]
--------------------------
POST /fs/_refresh <1>

GET /fs/lock/_search?scroll=1m <2>
{
    "sort" : ["_doc"],
    "query": {
        "match" : {
            "process_id" : 123
        }
    }
}

PUT /fs/lock/_bulk
{ "delete": { "_id": 1}}
{ "delete": { "_id": 2}}
--------------------------
<1> `refresh` 调用确保所有锁文档都是可见的搜索请求。
<2> 你可以使用 <<scroll,`scroll`>> 查询，当你需要通过单次搜索请求检索大量的结果集。

文档级锁可以实现细粒度的访问控制，但是为数百万文档创建锁文件开销也很大。
在某些情况下，你可以用少得多的工作量实现细粒度的锁定，如以下目录树场景中所示。

[[tree-locking]]
==== 树锁

在前面的例子中，我们可以锁定的目录树的一部分，而不是锁定每一个涉及的文件。((("locking", "tree locking")))
我们将需要独占访问我们要重命名的文件或目录，它可以通过 _独占锁_ 文档来实现：

[source,json]
--------------------------
{ "lock_type": "exclusive" }
--------------------------

并且我们需要在任何父目录上共享锁，通过 _共享锁_ 文档：

[source,json]
--------------------------
{
  "lock_type":  "shared",
  "lock_count": 1 <1>
}
--------------------------
<1> `lock_count` 记录持有共享锁进程的数量。

希望对 `/clinton/projects/elasticsearch/README.txt` 进行重命名的进程需要在这个文件上有 _独占锁_ ，
以及在 `/clinton` 、 `/clinton/projects` 和 `/clinton/projects/elasticsearch` 有 _共享锁_ 。

一个简单的 `create` 请求将满足独占锁的需要，但共享锁需要脚本的更新来实现一些额外的逻辑：

[source,groovy]
--------------------------
if (ctx._source.lock_type == 'exclusive') {
  assert false; <1>
}
ctx._source.lock_count++ <2>
--------------------------
<1> 如果 `lock_type` 是 `exclusive` 的，`assert` 语句将抛出一个异常，导致更新请求失败。
<2> 否则，我们对 `lock_count` 进行增量处理。

这个脚本处理了 `lock` 文档已经存在的情况，但我们还需要一个 `upsert` 文档用来处理的文档还不存在情况。
完整的更新请求如下：

[source,json]
--------------------------
POST /fs/lock/%2Fclinton/_update <1>
{
  "upsert": { <2>
    "lock_type":  "shared",
    "lock_count": 1
  },
  "script": "if (ctx._source.lock_type == 'exclusive')
  { assert false }; ctx._source.lock_count++"
}
--------------------------
<1> 文档的 ID 是 `/clinton` ，经过URL编码后成为 `%2fclinton` 。
<2> `upsert` 文档如果不存在，则会被插入。

一旦我们成功地在所有的父目录中获得一个共享锁，我们尝试在文件本身 `create` 一个独占锁：

[source,json]
--------------------------
PUT /fs/lock/%2Fclinton%2fprojects%2felasticsearch%2fREADME.txt/_create
{ "lock_type": "exclusive" }
--------------------------

现在，如果有其他人想要重新命名 `/clinton` 目录，他们将不得不在这条路径上获得一个独占锁：

[source,json]
--------------------------
PUT /fs/lock/%2Fclinton/_create
{ "lock_type": "exclusive" }
--------------------------

这个请求将失败，因为一个具有相同 ID 的 `lock` 文档已经存在。
另一个用户将不得不等待我们的操作完成以及释放我们的锁。独占锁只能这样被删除：

[source,json]
--------------------------
DELETE /fs/lock/%2Fclinton%2fprojects%2felasticsearch%2fREADME.txt
--------------------------

共享锁需要另一个脚本对 `lock_count` 递减，如果计数下降到零，删除 `lock` 文档：

[source,groovy]
--------------------------
if (--ctx._source.lock_count == 0) {
  ctx.op = 'delete' <1>
}
--------------------------
<1> 一旦 `lock_count` 达到0， `ctx.op` 会从 `update` 被修改成  `delete` 。

此更新请求将逆序为每个父目录运行，从最长到最短：

[source,json]
--------------------------
POST /fs/lock/%2Fclinton%2fprojects%2felasticsearch/_update
{
  "script": "if (--ctx._source.lock_count == 0) { ctx.op = 'delete' } "
}
--------------------------

树锁用最小的代价提供了细粒度的并发控制。当然，它不适用于所有的情况--如目录树在某些工作场景中，数据模型必须按顺序访问路径。

[NOTE]
=====================================

这三个方案--全局、文档或树锁--都没有处理锁最棘手的问题：如果持有锁的进程死了怎么办？

一个进程的意外死亡给我们留下了2个问题：

* 我们如何知道我们可以释放的死亡进程中所持有的锁？
* 我们如何清理死去的进程没有完成的变更？

这些主题超出了本书的范围，但是如果你决定使用锁，你需要给对他们进行一些思考。

=====================================

当非规范化是许多项目的一个很好的选择时，需要锁方案会带来复杂的实现逻辑。
作为替代方案，Elasticsearch 提供两个模型帮助我们处理相关联的实体： _嵌套的对象_ 和 _亲子关系_ 。
